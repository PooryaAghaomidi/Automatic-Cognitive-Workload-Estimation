{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "wl_NOreshape_run1.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "kLdgG6oKfr7L",
    "lPsQB_1pgNuw",
    "O0Z5i2a3gARm",
    "8Kt6jnr9jtzg",
    "j_FHubP0j1xR",
    "-1zEqmuCknco"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLdgG6oKfr7L"
   },
   "source": [
    "# **import libraries, data and label**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2ga-vebpi3Sk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d2b99fe0-6f8c-44ba-f940-ce2140a5b132"
   },
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adagrad, SGD, Adamax, RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (BatchNormalization, GlobalAveragePooling1D, Dense, Activation, Dropout, Flatten,\n",
    "                          Conv1D, MaxPooling1D, AveragePooling1D)\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Google Drive mount for Colab\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "# Set parameters\n",
    "size = 840  # Size parameter\n",
    "np.random.seed(10)  # Set seed for reproducibility\n",
    "number_of_classes = 2  # Number of output classes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w3byaVAVM8Ps"
   },
   "source": [
    "# Load labels\n",
    "mypath = '/content/drive/My Drive/valdata/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "ll = [f for f in onlyfiles if f[0] == 'w']\n",
    "lbl = sio.loadmat(mypath + ll[0])['wlbl']\n",
    "lbl = np.reshape(lbl, (840,))\n",
    "\n",
    "# Load data and gather information\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "mats = [f for f in onlyfiles if f[4] == 'm']\n",
    "mats = sorted(mats)\n",
    "\n",
    "# Windowing\n",
    "window = 5 * 500\n",
    "overlap = 4 * 500\n",
    "diff = window - overlap\n",
    "\n",
    "X = np.zeros((1, window))\n",
    "label = np.zeros((1, 1))\n",
    "\n",
    "for i in range(size):\n",
    "    temp = sio.loadmat(mypath + mats[i])['val'][0, :]\n",
    "    number_of_windows = math.floor((len(temp) - overlap) / diff)\n",
    "\n",
    "    for j in range(number_of_windows):\n",
    "        Xw = np.zeros((1, window))\n",
    "        Xw[0, :] = temp[diff * j: window + diff * j]\n",
    "        X = np.vstack((X, Xw))\n",
    "\n",
    "        lblw = np.zeros((1, 1))\n",
    "        lblw[0, 0] = lbl[i]\n",
    "        label = np.vstack((label, lblw))\n",
    "\n",
    "X = np.delete(X, 0, 0)\n",
    "label = np.delete(label, 0, 0)\n",
    "\n",
    "# Save processed data to CSV files\n",
    "np.savetxt(\"/content/drive/My Drive/valdata/X_no_reshape.csv\", X, delimiter = \",\")\n",
    "np.savetxt(\"/content/drive/My Drive/valdata/label_no_reshape.csv\", label, delimiter = \",\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hui9CiDxWveO"
   },
   "source": [
    "# load ready data and label\n",
    "X = np.loadtxt(\"/content/drive/My Drive/valdata/X_no_reshape.csv\", delimiter = \",\")\n",
    "label = np.loadtxt(\"/content/drive/My Drive/valdata/label_no_reshape.csv\", delimiter = \",\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPsQB_1pgNuw"
   },
   "source": [
    "# **data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SHTMWop_gLhv"
   },
   "source": [
    "# Function for picking the right class among outputs\n",
    "def change(x):\n",
    "    \"\"\"\n",
    "    Finds the class with the highest probability from the output layer.\n",
    "    \n",
    "    Args:\n",
    "    x (numpy.ndarray): Output layer array from the model.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of the index with the highest probability for each entry.\n",
    "    \"\"\"\n",
    "    answer = np.zeros((np.shape(x)[0]))\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        max_value = max(x[i, :])\n",
    "        max_index = list(x[i, :]).index(max_value)\n",
    "        answer[i] = max_index\n",
    "    return answer.astype(np.int)\n",
    "\n",
    "\n",
    "# Convert integer labels to binary representation\n",
    "Label_set = np.zeros((np.shape(label)[0], number_of_classes))\n",
    "for i in range(81480):\n",
    "    row = np.zeros((number_of_classes))\n",
    "    row[int(label[i]) - 1] = 1\n",
    "    Label_set[i, :] = row\n",
    "\n",
    "# Normalization\n",
    "Xnew = (X - X.mean()) / (X.std())\n",
    "Xnew = np.reshape(Xnew, (np.shape(Xnew)[0], np.shape(Xnew)[1], 1))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_o3F-dltYJ6H"
   },
   "source": [
    "# Train and test split - 5th slot as test\n",
    "values = [i for i in range(80640)]\n",
    "permutations = np.random.permutation(values)  # Generate a random permutation of indexes\n",
    "Xnew = Xnew[permutations, :]  # Apply permutation to the feature data\n",
    "Label_set = Label_set[permutations, :]  # Apply permutation to the label data\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train = Xnew[:int(0.8 * 80640), :]  # 80% for training\n",
    "Y_train = Label_set[:int(0.8 * 80640), :]  # Corresponding labels for training\n",
    "X_test = Xnew[int(0.8 * 80640):, :]  # Remaining 20% for testing\n",
    "Y_test = Label_set[int(0.8 * 80640):, :]  # Corresponding labels for testing\n",
    "sizee = len(X_test)\n",
    "\n",
    "val = 0.5  # Split the test data for validation\n",
    "X_val = X_test[:int(val * sizee), :]  # 50% for validation\n",
    "Y_val = Y_test[:int(val * sizee), :]  # Corresponding labels for validation\n",
    "X_test = X_test[int(val * sizee):, :]  # Remaining 50% for final testing\n",
    "Y_test = Y_test[int(val * sizee):, :]  # Corresponding labels for final testing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yJPWH1BoYKj-"
   },
   "source": [
    "# Train and test split - 4th slot as test\n",
    "values = [i for i in range(80640)]\n",
    "permutations = np.random.permutation(values)  # Generate a random permutation of indexes\n",
    "Xnew = Xnew[permutations, :]  # Apply permutation to the feature data\n",
    "Label_set = Label_set[permutations, :]  # Apply permutation to the label data\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train1 = Xnew[:int(0.6 * 80640), :]  # 60% for the first part of training\n",
    "X_train2 = Xnew[int(0.8 * 80640):, :]  # 20% for the second part of training\n",
    "X_train = np.vstack((X_train1, X_train2))  # Combine both parts for the complete training set\n",
    "Y_train1 = Label_set[:int(0.6 * 80640), :]  # Corresponding labels for the first part of training\n",
    "Y_train2 = Label_set[int(0.8 * 80640):, :]  # Corresponding labels for the second part of training\n",
    "Y_train = np.vstack((Y_train1, Y_train2))  # Combine both parts for the complete training labels\n",
    "\n",
    "X_test = Xnew[int(0.6 * 80640):int(0.8 * 80640), :]  # 20% for testing\n",
    "Y_test = Label_set[int(0.6 * 80640):int(0.8 * 80640), :]  # Corresponding labels for testing\n",
    "sizee = len(X_test)\n",
    "\n",
    "val = 0.5  # Split the test data for validation\n",
    "X_val = X_test[:int(val * sizee), :]  # 50% for validation\n",
    "Y_val = Y_test[:int(val * sizee), :]  # Corresponding labels for validation\n",
    "X_test = X_test[int(val * sizee):, :]  # Remaining 50% for final testing\n",
    "Y_test = Y_test[int(val * sizee):, :]  # Corresponding labels for final testing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1wgTVSENYMJx"
   },
   "source": [
    "# Train and test split - 3rd slot as test\n",
    "values = [i for i in range(80640)]\n",
    "permutations = np.random.permutation(values)  # Generate a random permutation of indexes\n",
    "Xnew = Xnew[permutations, :]  # Apply permutation to the feature data\n",
    "Label_set = Label_set[permutations, :]  # Apply permutation to the label data\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train1 = Xnew[:int(0.4 * 80640), :]  # 40% for the first part of training\n",
    "X_train2 = Xnew[int(0.6 * 80640):, :]  # 20% for the second part of training\n",
    "X_train = np.vstack((X_train1, X_train2))  # Combine both parts for the complete training set\n",
    "Y_train1 = Label_set[:int(0.4 * 80640), :]  # Corresponding labels for the first part of training\n",
    "Y_train2 = Label_set[int(0.6 * 80640):, :]  # Corresponding labels for the second part of training\n",
    "Y_train = np.vstack((Y_train1, Y_train2))  # Combine both parts for the complete training labels\n",
    "\n",
    "X_test = Xnew[int(0.4 * 80640):int(0.6 * 80640), :]  # 20% for testing\n",
    "Y_test = Label_set[int(0.4 * 80640):int(0.6 * 80640), :]  # Corresponding labels for testing\n",
    "sizee = len(X_test)\n",
    "\n",
    "val = 0.5  # Split the test data for validation\n",
    "X_val = X_test[:int(val * sizee), :]  # 50% for validation\n",
    "Y_val = Y_test[:int(val * sizee), :]  # Corresponding labels for validation\n",
    "X_test = X_test[int(val * sizee):, :]  # Remaining 50% for final testing\n",
    "Y_test = Y_test[int(val * sizee):, :]  # Corresponding labels for final testing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oHRbnoDaYNod"
   },
   "source": [
    "# Train and test split - 2nd slot as test\n",
    "values = [i for i in range(80640)]\n",
    "permutations = np.random.permutation(values)  # Create a random permutation of indexes\n",
    "Xnew = Xnew[permutations, :]  # Apply the permutation to the feature data\n",
    "Label_set = Label_set[permutations, :]  # Apply the permutation to the label data\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train1 = Xnew[:int(0.2 * 80640), :]  # 20% of the data for the first part of training\n",
    "X_train2 = Xnew[int(0.4 * 80640):, :]  # 40% for the second part of training\n",
    "X_train = np.vstack((X_train1, X_train2))  # Combine both parts for the complete training set\n",
    "Y_train1 = Label_set[:int(0.2 * 80640), :]  # Corresponding labels for the first part of training\n",
    "Y_train2 = Label_set[int(0.4 * 80640):, :]  # Corresponding labels for the second part of training\n",
    "Y_train = np.vstack((Y_train1, Y_train2))  # Combine both parts for the complete training labels\n",
    "\n",
    "X_test = Xnew[int(0.2 * 80640):int(0.4 * 80640), :]  # 20% for testing\n",
    "Y_test = Label_set[int(0.2 * 80640):int(0.4 * 80640), :]  # Corresponding labels for testing\n",
    "sizee = len(X_test)\n",
    "\n",
    "val = 0.5  # Split the test data for validation\n",
    "X_val = X_test[:int(val * sizee), :]  # 50% for validation\n",
    "Y_val = Y_test[:int(val * sizee), :]  # Corresponding labels for validation\n",
    "X_test = X_test[int(val * sizee):, :]  # Remaining 50% for final testing\n",
    "Y_test = Y_test[int(val * sizee):, :]  # Corresponding labels for final testing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TyXb-XlaYPF1"
   },
   "source": [
    "# Train and test split - 1st slot as test\n",
    "values = [i for i in range(80640)]\n",
    "permutations = np.random.permutation(values)  # Create a random permutation of indexes\n",
    "Xnew = Xnew[permutations, :]  # Apply the permutation to the feature data\n",
    "Label_set = Label_set[permutations, :]  # Apply the permutation to the label data\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train = Xnew[int(0.2 * 80640):, :]  # 80% of the data for training\n",
    "Y_train = Label_set[int(0.2 * 80640):, :]  # Corresponding labels for training\n",
    "X_test = Xnew[:int(0.2 * 80640), :]  # 20% for testing\n",
    "Y_test = Label_set[:int(0.2 * 80640), :]  # Corresponding labels for testing\n",
    "sizee = len(X_test)\n",
    "\n",
    "val = 0.5  # Split the test data for validation\n",
    "X_val = X_test[:int(val * sizee), :]  # 50% for validation\n",
    "Y_val = Y_test[:int(val * sizee), :]  # Corresponding labels for validation\n",
    "X_test = X_test[int(val * sizee):, :]  # Remaining 50% for final testing\n",
    "Y_test = Y_test[int(val * sizee):, :]  # Corresponding labels for final testing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0Z5i2a3gARm"
   },
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EU3qtqQ_jK8O"
   },
   "source": [
    "def pretty_plot(history, field, fn):\n",
    "    \"\"\"\n",
    "    Creates visualizations to display the training and validation metrics over epochs.\n",
    "\n",
    "    Args:\n",
    "    - history (object): The training history object generated during model training.\n",
    "    - field (string): The specific metric to plot over epochs.\n",
    "    - fn (function): A function to determine the best index for the specified field in the validation data.\n",
    "\n",
    "    Returns:\n",
    "    - Visualization plots showing the specified field's performance over all epochs and the last 15% of epochs.\n",
    "\n",
    "    The function generates two plots:\n",
    "    1. Performance of the specified field (e.g., loss, accuracy) over all epochs with a marker for the best value.\n",
    "    2. Performance of the specified field for the last 15% of epochs with a marker for the best value from the entire data.\n",
    "\n",
    "    The best index and value are determined using the provided function on the validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    def plot(data, val_data, best_index, best_value, title):\n",
    "        # Plot train and validation data with optional markers for the best index and value\n",
    "        plt.plot(range(1, len(data) + 1), data, label = 'train')  # Plot training data\n",
    "        plt.plot(range(1, len(data) + 1), val_data, label = 'validation')  # Plot validation data\n",
    "        if best_index is not None:\n",
    "            plt.axvline(x = best_index + 1, linestyle = ':', c = \"#777777\")  # Vertical line for best index\n",
    "        if best_value is not None:\n",
    "            plt.axhline(y = best_value, linestyle = ':', c = \"#777777\")  # Horizontal line for best value\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(field)\n",
    "        plt.xticks(range(0, len(data), 20))  # Set the ticks on the x-axis for every 20 epochs\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    data = history.history[field]  # Extract the specified field from the history\n",
    "    val_data = history.history['val_' + field]  # Extract the corresponding validation data\n",
    "    tail = int(0.15 * len(data))  # Extract the last 15% of the data\n",
    "\n",
    "    best_index = fn(val_data)  # Get the best index using the provided function\n",
    "    best_value = val_data[best_index]  # Get the best value from the validation data\n",
    "\n",
    "    # Plot for entire epochs and for the last 15% of the data\n",
    "    plot(data, val_data, best_index, best_value, \"{} over epochs (best {:06.4f})\".format(field, best_value))\n",
    "    plot(data[-tail:], val_data[-tail:], None, best_value, \"{} over last {} epochs\".format(field, tail))\n",
    "\n",
    "\n",
    "#learning rate finder\n",
    "from tf.keras.callbacks import Callback\n",
    "import tf.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LRFinder(Callback):\n",
    "    \"\"\"\n",
    "    Up-to date version: https://github.com/WittmannF/LRFinder\n",
    "    Example of usage:\n",
    "        from keras.models import Sequential\n",
    "        from keras.layers import Flatten, Dense\n",
    "        from keras.datasets import fashion_mnist\n",
    "        !git clone https://github.com/WittmannF/LRFinder.git\n",
    "        from LRFinder.keras_callback import LRFinder\n",
    "        # 1. Input Data\n",
    "        (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "        mean, std = X_train.mean(), X_train.std()\n",
    "        X_train, X_test = (X_train-mean)/std, (X_test-mean)/std\n",
    "        # 2. Define and Compile Model\n",
    "        model = Sequential([Flatten(),\n",
    "                            Dense(512, activation='relu'),\n",
    "                            Dense(10, activation='softmax')])\n",
    "        model.compile(loss='sparse_categorical_crossentropy', \\\n",
    "                      metrics=['accuracy'], optimizer='sgd')\n",
    "        # 3. Fit using Callback\n",
    "        lr_finder = LRFinder(min_lr=1e-4, max_lr=1)\n",
    "        model.fit(X_train, y_train, batch_size=128, callbacks=[lr_finder], epochs=2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_lr, max_lr, mom=0.9, stop_multiplier=None,\n",
    "                 reload_weights=True, batches_lr_update=5):\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.mom = mom\n",
    "        self.reload_weights = reload_weights\n",
    "        self.batches_lr_update = batches_lr_update\n",
    "        if stop_multiplier is None:\n",
    "            self.stop_multiplier = -20 * self.mom / 3 + 10  # 4 if mom=0.9\n",
    "            # 10 if mom=0\n",
    "        else:\n",
    "            self.stop_multiplier = stop_multiplier\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        p = self.params\n",
    "        try:\n",
    "            n_iterations = p['epochs'] * p['samples'] // p['batch_size']\n",
    "        except:\n",
    "            n_iterations = p['steps'] * p['epochs']\n",
    "\n",
    "        self.learning_rates = np.geomspace(self.min_lr, self.max_lr, \\\n",
    "                                           num = n_iterations // self.batches_lr_update + 1)\n",
    "        self.losses = []\n",
    "        self.iteration = 0\n",
    "        self.best_loss = 0\n",
    "        if self.reload_weights:\n",
    "            self.model.save_weights('tmp.hdf5')\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        loss = logs.get('loss')\n",
    "\n",
    "        if self.iteration != 0:  # Make loss smoother using momentum\n",
    "            loss = self.losses[-1] * self.mom + loss * (1 - self.mom)\n",
    "\n",
    "        if self.iteration == 0 or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "\n",
    "        if self.iteration % self.batches_lr_update == 0:  # Evaluate each lr over 5 epochs\n",
    "\n",
    "            if self.reload_weights:\n",
    "                self.model.load_weights('tmp.hdf5')\n",
    "\n",
    "            lr = self.learning_rates[self.iteration // self.batches_lr_update]\n",
    "            K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "            self.losses.append(loss)\n",
    "\n",
    "        if loss > self.best_loss * self.stop_multiplier:  # Stop criteria\n",
    "            self.model.stop_training = True\n",
    "\n",
    "        self.iteration += 1\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.reload_weights:\n",
    "            self.model.load_weights('tmp.hdf5')\n",
    "\n",
    "        plt.figure(figsize = (12, 6))\n",
    "        plt.plot(self.learning_rates[:len(self.losses)], self.losses)\n",
    "        plt.xlabel(\"Learning Rate\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xscale('log')\n",
    "        plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kt6jnr9jtzg"
   },
   "source": [
    "# **model structure**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GCM8QRuuqHYL"
   },
   "source": [
    "# Define the structure of the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv1D(32, 4, strides = 1, padding = 'same', activation = 'relu', input_shape = (2500, 1)))\n",
    "model.add(Conv1D(32, 4, strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling1D(4, 2))  # Down-sampling layer\n",
    "model.add(BatchNormalization())  # Normalize the activations\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv1D(64, 4, strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv1D(64, 4, strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling1D(4, 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv1D(128, 4, strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv1D(128, 4, strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling1D(4, 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "model.add(Conv1D(256, 4, strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv1D(256, 4, strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling1D(4, 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Global Average Pooling\n",
    "model.add(GlobalAveragePooling1D())  # Pooling layer for spatial data reduction\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Dense(256, kernel_initializer = 'normal', activation = 'relu'))  # Fully connected layer\n",
    "model.add(Dropout(0.2))  # Dropout layer for regularization\n",
    "model.add(Dense(2, kernel_initializer = 'normal', activation = 'softmax'))  # Output layer with Softmax activation for classification"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_FHubP0j1xR"
   },
   "source": [
    "# **train model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qbLcmXGUu50f"
   },
   "source": [
    "# Set the optimizer and compile the model\n",
    "optimizer = tf.keras.optimizers.Adamax(lr = 0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "# Learning Rate Finder\n",
    "lr_finder = LRFinder(min_lr = 1e-12, max_lr = 1e+1)\n",
    "\n",
    "# Fit the model to the training data using LR Finder callback to observe loss at different learning rates\n",
    "model.fit(X_train, Y_train, batch_size = 128, callbacks = [lr_finder], epochs = 5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MxFVEvymqJRd"
   },
   "source": [
    "# Configure optimizer and compile the model\n",
    "opt = Adamax(learning_rate = 0.001, decay = 0.001, clipvalue = 0.5, epsilon = 1e-07)\n",
    "model.compile(loss = 'mse', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "# Define the path for storing model and history\n",
    "pathh = '/content/drive/My Drive/Conv_models'\n",
    "\n",
    "# Create a callback to save the best model based on validation accuracy\n",
    "checkpointer = ModelCheckpoint(filepath = pathh, monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)\n",
    "\n",
    "# Train the model on the training data and validate on the validation set\n",
    "# Save the best model and the history to specified file paths\n",
    "hist = model.fit(X_train, Y_train, validation_data = (\n",
    "X_val, Y_val), batch_size = 128, epochs = 280, verbose = 2, shuffle = True, callbacks = [checkpointer])\n",
    "pd.DataFrame(hist.history).to_csv(path_or_buf = '/content/drive/My Drive/Conv_models/History.csv')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1zEqmuCknco"
   },
   "source": [
    "# **train information**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "neI_Jh4Krtos",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "a6017998-8908-45ff-cf1b-4b26cb0272f5"
   },
   "source": [
    "#plot run info\n",
    "pretty_plot(hist, 'loss', lambda x: np.argmin(x))\n",
    "pretty_plot(hist, 'accuracy', lambda x: np.argmax(x))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ry2w3xlosikV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "67f87ba9-4d03-48bd-9b68-8eaedd5cd098"
   },
   "source": [
    "#test\n",
    "testmodel = load_model('/content/drive/My Drive/Conv_models')\n",
    "tst_loss, tst_acc = testmodel.evaluate(X_test, Y_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CLwFjuOhWJwb"
   },
   "source": [
    "#print model summary\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GYjGQojxWKOX"
   },
   "source": [
    "# Initialize arrays for model evaluation metrics\n",
    "accuracy_model = np.zeros((1, 1))\n",
    "Sensitivity_model = np.zeros((1, 1))\n",
    "Specificity_model = np.zeros((1, 1))\n",
    "\n",
    "# Get predictions from the model and compute the confusion matrix\n",
    "Y_pred = model.predict(X_test, verbose = 0, max_queue_size = 10, workers = 1, use_multiprocessing = False)\n",
    "cm = confusion_matrix(change(Y_test), change(Y_pred))\n",
    "\n",
    "# Calculate accuracy, sensitivity, and specificity from the confusion matrix\n",
    "accuracy_model = accuracy_score(change(Y_test), change(Y_pred))\n",
    "Sensitivity_model = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "Specificity_model = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "# Calculate ROC AUC score using predictions and actual labels\n",
    "auc = roc_auc_score(Y_test, Y_pred, average = 'macro', sample_weight = None, max_fpr = None, multi_class = 'raise', labels = None)\n",
    "\n",
    "# Display the evaluation metrics and classification report\n",
    "print('\\n\\n\\n\\n roc_auc_score : \\n', auc)\n",
    "print('\\n\\n confusion_matrix : \\n', cm)\n",
    "print('\\n\\n test accuracy is :', accuracy_model)\n",
    "print(' Sensitivity :', Sensitivity_model)\n",
    "print(' Specificity :', Specificity_model)\n",
    "print('\\n\\n classification report : \\n', classification_report(change(Y_test), change(Y_pred)))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
